{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aafffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from fasta_one_hot_encoder import FastaOneHotEncoder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06210fd9",
   "metadata": {},
   "source": [
    "## Convert fasta files into one hot encoded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c4fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = FastaOneHotEncoder(\n",
    "    nucleotides=\"acgt\",\n",
    "    lower = True,\n",
    "    sparse = False,\n",
    "    handle_unknown = \"ignore\")\n",
    "for fasta in glob.glob(\"../chroms/*.fa\"):\n",
    "    path = fasta\n",
    "    chr_tmp = encoder.transform_to_df(path, verbose=True)\n",
    "    print(path.split(\"/\")[-1].split(\".\")[0])\n",
    "    chr_tmp.to_csv(\"../chroms/oe_chroms/{}.csv\".format(path.split(\"/\")[-1].split(\".\")[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6475a",
   "metadata": {},
   "source": [
    "## Create training data from one hot encoded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before running, increase file descriptor limit\n",
    "# resource.setrlimit(resource.RLIMIT_NOFILE, (131072, 131072))\n",
    "# print (\"getrlimit:\", resource.getrlimit(resource.RLIMIT_NOFILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSeqData(chromosomes, step=200, nuc_context=1000):\n",
    "    pol3_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\"]\n",
    "    pol3_df = pd.read_csv(\"../data/polr3d.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "    for chrom in chromosomes:\n",
    "        print(chrom+\":\")\n",
    "        print(\"     Creating necessary directories...\")\n",
    "        output_dir1 = \"../data/tmp_seqData/\"\n",
    "        output_dir2 = \"../data/chr_seqData/\"\n",
    "        if not os.path.exists(output_dir1):\n",
    "            os.makedirs(output_dir1)\n",
    "        if not os.path.exists(output_dir2):\n",
    "            os.makedirs(output_dir2)\n",
    "            \n",
    "        #Process chromosome oe df to create training data\n",
    "        print(\"     Processing one-hot encoded dataframe...\")\n",
    "        chr_df = pd.read_csv(\"../chroms/oe_chroms/{}.csv\".format(chrom))\n",
    "        chr_df[\"Label\"] = 0\n",
    "        pol3_chr_df = pol3_df[pol3_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "        for row in range(len(pol3_chr_df)):\n",
    "            beg_range = pol3_chr_df.iloc[row][\"Start\"]\n",
    "            end_range = pol3_chr_df.iloc[row][\"End\"]\n",
    "            chr_df.loc[beg_range:end_range, \"Label\"] = 1\n",
    "\n",
    "        print(\"     Creating training data. This may take a while...\")\n",
    "        #Start creating training data\n",
    "        labels = []\n",
    "        file_names = []\n",
    "        final_data = []\n",
    "        j = 1\n",
    "        #Get first and last non-N index\n",
    "        fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "        for seq in fasta_sequences:\n",
    "            name, sequence = seq.id, str(seq.seq)\n",
    "        a_idx = sequence.lower().index(\"a\")\n",
    "        c_idx = sequence.lower().index(\"c\")\n",
    "        g_idx = sequence.lower().index(\"g\")\n",
    "        t_idx = sequence.lower().index(\"t\")\n",
    "        chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "        a_idx = sequence.lower().rfind(\"a\")\n",
    "        c_idx = sequence.lower().rfind(\"c\")\n",
    "        g_idx = sequence.lower().rfind(\"g\")\n",
    "        t_idx = sequence.lower().rfind(\"t\")\n",
    "        chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "        for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "            if i <= chr_end_idx:\n",
    "                beg_seq = []\n",
    "                end_seq = []\n",
    "                \n",
    "                start_idx = i - nuc_context\n",
    "                if start_idx < 0:\n",
    "                    start_idx = 0\n",
    "                    n_count = (i - nuc_context) * -1\n",
    "                    beg_seq = [[0,0,0,0]] * n_count\n",
    "                end_idx = i+step+nuc_context\n",
    "                if end_idx > len(chr_df):\n",
    "                    end_idx = len(chr_df)\n",
    "                    n_count = (i+step+nuc_context) - len(chr_df)\n",
    "                    end_seq = [[0,0,0,0]] * n_count\n",
    "\n",
    "                if beg_seq == [] and end_seq == []:\n",
    "                    training_seq = chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).to_numpy()\n",
    "                elif beg_seq == [] and len(end_seq) != 0:\n",
    "                    training_seq = chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).to_numpy() + np.array(end_seq)\n",
    "                elif len(beg_seq) != 0 and end_seq == []:\n",
    "                    training_seq = beg_seq + chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).values.tolist()\n",
    "                #Determine labels    \n",
    "                tmp_df = chr_df[start_idx:end_idx]\n",
    "                grouped_df = tmp_df.groupby(\"Label\").count().reset_index()\n",
    "                try:\n",
    "                    if grouped_df[grouped_df[\"Label\"] == 1][\"Unnamed: 0\"][1] >= 65:\n",
    "                        labels.append([1])\n",
    "                    else:\n",
    "                        labels.append([0])\n",
    "                except KeyError:\n",
    "                    labels.append([0])\n",
    "                #Save temp files for later concatenation\n",
    "                training_seq = np.array([training_seq], dtype=np.uint16)\n",
    "                if j == 1: \n",
    "                    training_data = training_seq\n",
    "                else:\n",
    "                    training_data = np.append(training_data, training_seq, axis=0)\n",
    "                if j % 50 == 0:\n",
    "                    np.savez_compressed(\"../data/tmp_seqData/tmp_{}.npz\".format(i), training_data)\n",
    "                    file_names.append(\"../data/tmp_seqData/tmp_{}.npz\".format(i))\n",
    "                    j = 1\n",
    "                else:\n",
    "                    j+=1\n",
    "        del training_data\n",
    "        \n",
    "        print(\"     Finalizing training data...\")\n",
    "\n",
    "        #Open numpy npz files and memmap them to reduce memory usage\n",
    "        fpath = \"../data/chr_seqData/{}_seqData.dat\".format(chrom)\n",
    "        rows = 0\n",
    "        cols = None\n",
    "        dtype = None\n",
    "        for data_file in file_names:\n",
    "            with np.load(data_file) as data:\n",
    "                for item in data.files:\n",
    "                    chunk = data[item]\n",
    "                    rows += chunk.shape[0]\n",
    "                    cols = chunk.shape[1]\n",
    "                    elements = chunk.shape[2]\n",
    "                    dtype = chunk.dtype\n",
    "                \n",
    "        merged = np.memmap(fpath, dtype=dtype, mode='w+', shape=(rows, cols, elements))\n",
    "        idx = 0\n",
    "        for data_file in file_names:\n",
    "            with np.load(data_file) as data:\n",
    "                for item in data.files:\n",
    "                    chunk = data[item]\n",
    "                    merged[idx:idx + len(chunk)] = chunk\n",
    "                    idx += len(chunk)\n",
    "                \n",
    "        #Save chr data\n",
    "        labels = np.array(labels)\n",
    "        fpath2 = \"../data/chr_seqData/{}_labelsData.npz\".format(chrom)\n",
    "        np.savez_compressed(fpath2, labels=labels)\n",
    "        \n",
    "        #Delete temp directories\n",
    "        dir = '../data/tmp_seqData/'\n",
    "        shutil.rmtree(dir)\n",
    "        \n",
    "        print(\"Completed {}!\".format(chrom))\n",
    "        print(\"Memmap object dimensions:\", rows, columns, elements)\n",
    "        \n",
    "    print(\"Finished creating training data by chromosome!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2eedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createChipData(chromosomes, step=200, nuc_context=1000):\n",
    "    print(\"Reading in chip files...\")\n",
    "    chip_dfs = []\n",
    "    chip_names = []\n",
    "    chip_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\", \"signalValue\", \"pValue\", \"qValue\", \"peak\"]\n",
    "    for chip in glob.glob(\"../data/chip_data/*\"):\n",
    "        tmp_chip_df = pd.read_csv(chip, sep=\"\\s+\", header=None, names=chip_bed_cols_names)\n",
    "        chip_dfs.append(tmp_chip_df)\n",
    "        chip_names.append(chip.split(\"/\")[-1].split(\".\")[0])\n",
    "    \n",
    "    for chrom in chromosomes:\n",
    "        print(chrom+\":\")\n",
    "        print(\"     Creating necessary directories...\")\n",
    "        output_dir1 = \"../data/tmp_chipData/\"\n",
    "        output_dir2 = \"../data/chr_chipData/\"\n",
    "        if not os.path.exists(output_dir1):\n",
    "            os.makedirs(output_dir1)\n",
    "        if not os.path.exists(output_dir2):\n",
    "            os.makedirs(output_dir2)\n",
    "            \n",
    "        #Process chromosome oe df to create training data\n",
    "        print(\"     Reading in one-hot encoded dataframe...\")\n",
    "        chr_df = pd.read_csv(\"../chroms/oe_chroms/{}.csv\".format(chrom))\n",
    "            \n",
    "        #Create ChIP df that is ready to be converted to numpy training data\n",
    "        print(\"     Processing ChIP data...\")\n",
    "        chip_df = pd.DataFrame(index=np.arange(len(chr_df))).reset_index().drop(columns=\"index\")\n",
    "        chip_idx = 0\n",
    "        for chip in chip_dfs:\n",
    "            tmp_chip_chr_df = chip[chip[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "            chip_df[chip_names[chip_idx]] = 0.\n",
    "            \n",
    "            for row in range(len(tmp_chip_chr_df)):\n",
    "                beg_range = tmp_chip_chr_df.iloc[row][\"Start\"]\n",
    "                end_range = tmp_chip_chr_df.iloc[row][\"End\"]\n",
    "                chip_df.loc[beg_range:end_range, chip_names[chip_idx]] = tmp_chip_chr_df.iloc[row][\"signalValue\"]\n",
    "            chip_idx+=1\n",
    "                        \n",
    "\n",
    "        print(\"     Creating training data. This may take a while...\")\n",
    "        #Start creating training data\n",
    "        file_names = []\n",
    "        final_data = []\n",
    "        j = 1\n",
    "        #Get first and last non-N index\n",
    "        fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "        for seq in fasta_sequences:\n",
    "            name, sequence = seq.id, str(seq.seq)\n",
    "        a_idx = sequence.lower().index(\"a\")\n",
    "        c_idx = sequence.lower().index(\"c\")\n",
    "        g_idx = sequence.lower().index(\"g\")\n",
    "        t_idx = sequence.lower().index(\"t\")\n",
    "        chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "        a_idx = sequence.lower().rfind(\"a\")\n",
    "        c_idx = sequence.lower().rfind(\"c\")\n",
    "        g_idx = sequence.lower().rfind(\"g\")\n",
    "        t_idx = sequence.lower().rfind(\"t\")\n",
    "        chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "        for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "            if i <= chr_end_idx:\n",
    "                beg_seq = []\n",
    "                end_seq = []\n",
    "                \n",
    "                start_idx = i - nuc_context\n",
    "                if start_idx < 0:\n",
    "                    start_idx = 0\n",
    "                    n_count = (i - nuc_context) * -1\n",
    "                    beg_seq = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "                end_idx = i+step+nuc_context\n",
    "                if end_idx > len(chr_df):\n",
    "                    end_idx = len(chr_df)\n",
    "                    n_count = (i+step+nuc_context) - len(chr_df)\n",
    "                    end_seq = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "\n",
    "                if beg_seq == [] and end_seq == []:\n",
    "                    training_seq = chip_df[start_idx:end_idx].to_numpy()\n",
    "                elif beg_seq == [] and len(end_seq) != 0:\n",
    "                    training_seq = chip_df[start_idx:end_idx].to_numpy() + np.array(end_seq)\n",
    "                elif len(beg_seq) != 0 and end_seq == []:\n",
    "                    training_seq = beg_seq + chip_df[start_idx:end_idx].values.tolist()\n",
    "\n",
    "                #Save temp files for later concatenation\n",
    "                training_seq = np.array([training_seq], dtype=np.float32)\n",
    "                if j == 1: \n",
    "                    training_data = training_seq\n",
    "                else:\n",
    "                    training_data = np.append(training_data, training_seq, axis=0)\n",
    "                if j % 50 == 0:\n",
    "                    \n",
    "                    np.savez_compressed(\"../data/tmp_chipData/tmp_{}.npz\".format(i), training_data)\n",
    "                    file_names.append(\"../data/tmp_chipData/tmp_{}.npz\".format(i))\n",
    "                    j = 1\n",
    "                else:\n",
    "                    j+=1\n",
    "        del training_data\n",
    "        \n",
    "        print(\"     Finalizing training data...\")\n",
    "        #Open numpy npz files and memmap them to reduce memory usage\n",
    "        fpath = \"../data/chr_chipData/{}_chipData.dat\".format(chrom)\n",
    "        rows = 0\n",
    "        cols = None\n",
    "        dtype = None\n",
    "        for data_file in file_names:\n",
    "            with np.load(data_file) as data:\n",
    "                for item in data.files:\n",
    "                    chunk = data[item]\n",
    "                    rows += chunk.shape[0]\n",
    "                    cols = chunk.shape[1]\n",
    "                    elements = chunk.shape[2]\n",
    "                    dtype = chunk.dtype\n",
    "                \n",
    "        merged = np.memmap(fpath, dtype=dtype, mode='w+', shape=(rows, cols, elements))\n",
    "        idx = 0\n",
    "        for data_file in file_names:\n",
    "            with np.load(data_file) as data:\n",
    "                for item in data.files:\n",
    "                    chunk = data[item]\n",
    "                    merged[idx:idx + len(chunk)] = chunk\n",
    "                    idx += len(chunk)\n",
    "        \n",
    "        #Delete temp directories\n",
    "        dir = '../data/tmp_chipData/'\n",
    "        shutil.rmtree(dir)\n",
    "        \n",
    "        print(\"Completed {}!\".format(chrom))\n",
    "        print(\"Memmap object dimensions:\", rows, columns, elements)\n",
    "        \n",
    "    print(\"Finished creating training data by chromosome!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10287186",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_chroms = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\",\n",
    "                  \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"]\n",
    "testing_chroms = [\"chr7\", \"chr8\"]\n",
    "all_chroms = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\",\n",
    "                  \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"]\n",
    "test_chrom = [\"chrY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSeqData(all_chroms, step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "createChipData(all_chroms, step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbbfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example of how to write to memmap object\n",
    "# print(datetime.now())\n",
    "# rows = 0\n",
    "# cols = None\n",
    "# dtype = None\n",
    "# fpath = \"../data/chr_chipData/{}_chipData.npz\".format(\"chr7\")\n",
    "\n",
    "# print(\"Getting values for memmap...\")\n",
    "\n",
    "# for data_file in glob.glob(\"../data/tmp_chipData/*\"):\n",
    "#     with np.load(data_file) as data:\n",
    "#         for item in data.files:\n",
    "#             chunk = data[item]\n",
    "#             rows += chunk.shape[0]\n",
    "#             cols = chunk.shape[1]\n",
    "#             dtype = chunk.dtype\n",
    "\n",
    "# print(\"Creating memmap object...\")\n",
    "# merged = np.memmap(fpath, dtype=dtype, mode='w+', shape=(rows, cols, 20))\n",
    "# idx = 0\n",
    "# print(\"Setting values in memmap object...\")\n",
    "# for data_file in glob.glob(\"../data/tmp_chipData/*\"):\n",
    "#     with np.load(data_file) as data:\n",
    "#         for item in data.files:\n",
    "#             chunk = data[item]\n",
    "#             merged[idx:idx + len(chunk)] = chunk\n",
    "#             idx += len(chunk)\n",
    "# print(datetime.now())\n",
    "# print(\"Completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example of how to open memmap object\n",
    "# npfile = \"../data/chr_seqData/{}_seqData.dat\".format(\"chrY\")\n",
    "# test = np.memmap(npfile, dtype='float32', mode='r', shape=(rows,columns,elements))\n",
    "# test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
