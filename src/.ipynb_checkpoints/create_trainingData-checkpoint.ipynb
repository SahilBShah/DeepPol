{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8aafffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "from fasta_one_hot_encoder import FastaOneHotEncoder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06210fd9",
   "metadata": {},
   "source": [
    "## Convert fasta files into one hot encoded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61c4fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder = FastaOneHotEncoder(\n",
    "#     nucleotides=\"acgt\",\n",
    "#     lower = True,\n",
    "#     sparse = False,\n",
    "#     handle_unknown = \"ignore\")\n",
    "# for fasta in glob.glob(\"../chroms/*.fa\"):\n",
    "#     path = fasta\n",
    "#     chr_tmp = encoder.transform_to_df(path, verbose=True)\n",
    "#     print(path.split(\"/\")[-1].split(\".\")[0])\n",
    "#     chr_tmp.to_csv(\"../chroms/oe_chroms/{}.csv\".format(path.split(\"/\")[-1].split(\".\")[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6475a",
   "metadata": {},
   "source": [
    "## Create training data from one hot encoded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b6453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before running, increase file descriptor limit\n",
    "# resource.setrlimit(resource.RLIMIT_NOFILE, (131072, 131072))\n",
    "# print (\"getrlimit:\", resource.getrlimit(resource.RLIMIT_NOFILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba4780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createSeqData(chromosomes, step=200, nuc_context=1000):\n",
    "#     pol3_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\"]\n",
    "#     pol3_df = pd.read_csv(\"../data/polr3d.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "#     rmsk_df = pd.read_csv(\"../data/mm10_rmsk.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "#     for chrom in chromosomes:\n",
    "#         print(chrom+\":\")\n",
    "#         print(\"     Creating necessary directories...\")\n",
    "#         output_dir1 = \"../data/tmp_seqData/\"\n",
    "#         output_dir2 = \"../data/chr_seqData/\"\n",
    "#         if not os.path.exists(output_dir1):\n",
    "#             os.makedirs(output_dir1)\n",
    "#         if not os.path.exists(output_dir2):\n",
    "#             os.makedirs(output_dir2)\n",
    "            \n",
    "#         #Process chromosome oe df to create training data\n",
    "#         print(\"     Processing one-hot encoded dataframe...\")\n",
    "#         chr_df = pd.read_csv(\"../chroms/oe_chroms/{}.csv\".format(chrom))\n",
    "#         chr_df[\"Label\"] = 0\n",
    "#         pol3_chr_df = pol3_df[pol3_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "#         rmsk_chr_df = rmsk_df[rmsk_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "        \n",
    "#         for row in range(len(rmsk_chr_df)):\n",
    "#             beg_range = rmsk_chr_df.iloc[row][\"Start\"]\n",
    "#             end_range = rmsk_chr_df.iloc[row][\"End\"]\n",
    "#             chr_df.loc[beg_range:end_range, \"Label\"] = 1\n",
    "#         for row in range(len(pol3_chr_df)):\n",
    "#             beg_range = pol3_chr_df.iloc[row][\"Start\"]\n",
    "#             end_range = pol3_chr_df.iloc[row][\"End\"]\n",
    "#             chr_df.loc[beg_range:end_range, \"Label\"] = 2\n",
    "\n",
    "#         print(\"     Creating training data. This may take a while...\")\n",
    "#         #Start creating training data\n",
    "#         labels = []\n",
    "#         file_names = []\n",
    "#         final_data = []\n",
    "#         j = 1\n",
    "#         #Get first and last non-N index\n",
    "#         fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "#         for seq in fasta_sequences:\n",
    "#             name, sequence = seq.id, str(seq.seq)\n",
    "#         a_idx = sequence.lower().index(\"a\")\n",
    "#         c_idx = sequence.lower().index(\"c\")\n",
    "#         g_idx = sequence.lower().index(\"g\")\n",
    "#         t_idx = sequence.lower().index(\"t\")\n",
    "#         chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "#         a_idx = sequence.lower().rfind(\"a\")\n",
    "#         c_idx = sequence.lower().rfind(\"c\")\n",
    "#         g_idx = sequence.lower().rfind(\"g\")\n",
    "#         t_idx = sequence.lower().rfind(\"t\")\n",
    "#         chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "#         for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "#             if i <= chr_end_idx:\n",
    "#                 beg_seq = []\n",
    "#                 end_seq = []\n",
    "                \n",
    "#                 start_idx = i - nuc_context\n",
    "#                 if start_idx < 0:\n",
    "#                     start_idx = 0\n",
    "#                     n_count = (i - nuc_context) * -1\n",
    "#                     beg_seq = [[0,0,0,0]] * n_count\n",
    "#                 end_idx = i+step+nuc_context\n",
    "#                 if end_idx > len(chr_df):\n",
    "#                     end_idx = len(chr_df)\n",
    "#                     n_count = (i+step+nuc_context) - len(chr_df)\n",
    "#                     end_seq = [[0,0,0,0]] * n_count\n",
    "\n",
    "#                 if beg_seq == [] and end_seq == []:\n",
    "#                     training_seq = chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).to_numpy()\n",
    "#                 elif beg_seq == [] and len(end_seq) != 0:\n",
    "#                     training_seq = chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).to_numpy() + np.array(end_seq)\n",
    "#                 elif len(beg_seq) != 0 and end_seq == []:\n",
    "#                     training_seq = beg_seq + chr_df[start_idx:end_idx].drop(columns=[\"Unnamed: 0\", \"Label\"]).values.tolist()\n",
    "#                 #Determine labels    \n",
    "#                 tmp_df = chr_df[start_idx:end_idx]\n",
    "#                 grouped_df = tmp_df.groupby(\"Label\").count().reset_index()\n",
    "#                 grouped_df.index = grouped_df[\"Label\"]\n",
    "#                 try:\n",
    "#                     if grouped_df[grouped_df[\"Label\"] == 2][\"Unnamed: 0\"][2] >= 65:\n",
    "#                         labels.append([1])\n",
    "#                     elif grouped_df[grouped_df[\"Label\"] == 1][\"Unnamed: 0\"][1] >= 65:\n",
    "#                         labels.append([0])\n",
    "#                     else:\n",
    "#                         labels.append([2])\n",
    "#                 except KeyError:\n",
    "#                     try:\n",
    "#                         if grouped_df[grouped_df[\"Label\"] == 1][\"Unnamed: 0\"][1] >= 65:\n",
    "#                             labels.append([0])\n",
    "#                         else:\n",
    "#                             labels.append([2])\n",
    "#                     except KeyError:\n",
    "#                         labels.append([2])\n",
    "#                 #Save temp files for later concatenation\n",
    "#                 training_seq = np.array([training_seq], dtype=np.uint16)\n",
    "#                 if j == 1: \n",
    "#                     training_data = training_seq\n",
    "#                 else:\n",
    "#                     training_data = np.append(training_data, training_seq, axis=0)\n",
    "#                 if j % 50 == 0:\n",
    "#                     np.savez_compressed(\"../data/tmp_seqData/tmp_{}.npz\".format(i), training_data)\n",
    "#                     file_names.append(\"../data/tmp_seqData/tmp_{}.npz\".format(i))\n",
    "#                     j = 1\n",
    "#                 else:\n",
    "#                     j+=1\n",
    "#         del training_data\n",
    "        \n",
    "#         print(\"     Finalizing training data...\")\n",
    "\n",
    "#         #Open numpy npz files and memmap them to reduce memory usage\n",
    "#         fpath = \"../data/chr_seqData/{}_seqData.dat\".format(chrom)\n",
    "#         rows = 0\n",
    "#         cols = None\n",
    "#         dtype = None\n",
    "#         for data_file in file_names:\n",
    "#             with np.load(data_file) as data:\n",
    "#                 for item in data.files:\n",
    "#                     chunk = data[item]\n",
    "#                     rows += chunk.shape[0]\n",
    "#                     cols = chunk.shape[1]\n",
    "#                     elements = chunk.shape[2]\n",
    "#                     dtype = chunk.dtype\n",
    "                \n",
    "#         merged = np.memmap(fpath, dtype=dtype, mode='w+', shape=(rows, cols, elements))\n",
    "#         idx = 0\n",
    "#         for data_file in file_names:\n",
    "#             with np.load(data_file) as data:\n",
    "#                 for item in data.files:\n",
    "#                     chunk = data[item]\n",
    "#                     merged[idx:idx + len(chunk)] = chunk\n",
    "#                     idx += len(chunk)\n",
    "                \n",
    "#         #Save chr data\n",
    "#         labels = np.array(labels)\n",
    "#         fpath2 = \"../data/chr_seqData/{}_labelsData.npz\".format(chrom)\n",
    "#         np.savez_compressed(fpath2, labels=labels)\n",
    "        \n",
    "#         #Delete temp directories\n",
    "#         dir = '../data/tmp_seqData/'\n",
    "#         shutil.rmtree(dir)\n",
    "        \n",
    "#         print(\"Completed {}!\".format(chrom))\n",
    "#         print(\"Memmap object dimensions:\", rows, columns, elements)\n",
    "        \n",
    "#     print(\"Finished creating training data by chromosome!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2eedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createChipData(chromosomes, step=200, nuc_context=1000):\n",
    "#     print(\"Reading in chip files...\")\n",
    "#     chip_dfs = []\n",
    "#     chip_names = []\n",
    "#     chip_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\", \"signalValue\", \"pValue\", \"qValue\", \"peak\"]\n",
    "#     for chip in glob.glob(\"../data/chip_data/*\"):\n",
    "#         tmp_chip_df = pd.read_csv(chip, sep=\"\\s+\", header=None, names=chip_bed_cols_names)\n",
    "#         chip_dfs.append(tmp_chip_df)\n",
    "#         chip_names.append(chip.split(\"/\")[-1].split(\".\")[0])\n",
    "    \n",
    "#     for chrom in chromosomes:\n",
    "#         print(chrom+\":\")\n",
    "#         print(\"     Creating necessary directories...\")\n",
    "#         output_dir1 = \"../data/tmp_chipData/\"\n",
    "#         output_dir2 = \"../data/chr_chipData/\"\n",
    "#         if not os.path.exists(output_dir1):\n",
    "#             os.makedirs(output_dir1)\n",
    "#         if not os.path.exists(output_dir2):\n",
    "#             os.makedirs(output_dir2)\n",
    "            \n",
    "#         #Process chromosome oe df to create training data\n",
    "#         print(\"     Reading in one-hot encoded dataframe...\")\n",
    "#         chr_df = pd.read_csv(\"../chroms/oe_chroms/{}.csv\".format(chrom))\n",
    "            \n",
    "#         #Create ChIP df that is ready to be converted to numpy training data\n",
    "#         print(\"     Processing ChIP data...\")\n",
    "#         chip_df = pd.DataFrame(index=np.arange(len(chr_df))).reset_index().drop(columns=\"index\")\n",
    "#         chip_idx = 0\n",
    "#         for chip in chip_dfs:\n",
    "#             tmp_chip_chr_df = chip[chip[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "#             chip_df[chip_names[chip_idx]] = 0.\n",
    "            \n",
    "#             for row in range(len(tmp_chip_chr_df)):\n",
    "#                 beg_range = tmp_chip_chr_df.iloc[row][\"Start\"]\n",
    "#                 end_range = tmp_chip_chr_df.iloc[row][\"End\"]\n",
    "#                 chip_df.loc[beg_range:end_range, chip_names[chip_idx]] = tmp_chip_chr_df.iloc[row][\"signalValue\"]\n",
    "#             chip_idx+=1\n",
    "                        \n",
    "\n",
    "#         print(\"     Creating training data. This may take a while...\")\n",
    "#         #Start creating training data\n",
    "#         file_names = []\n",
    "#         final_data = []\n",
    "#         j = 1\n",
    "#         #Get first and last non-N index\n",
    "#         fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "#         for seq in fasta_sequences:\n",
    "#             name, sequence = seq.id, str(seq.seq)\n",
    "#         a_idx = sequence.lower().index(\"a\")\n",
    "#         c_idx = sequence.lower().index(\"c\")\n",
    "#         g_idx = sequence.lower().index(\"g\")\n",
    "#         t_idx = sequence.lower().index(\"t\")\n",
    "#         chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "#         a_idx = sequence.lower().rfind(\"a\")\n",
    "#         c_idx = sequence.lower().rfind(\"c\")\n",
    "#         g_idx = sequence.lower().rfind(\"g\")\n",
    "#         t_idx = sequence.lower().rfind(\"t\")\n",
    "#         chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "#         for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "#             if i <= chr_end_idx:\n",
    "#                 beg_seq = []\n",
    "#                 end_seq = []\n",
    "                \n",
    "#                 start_idx = i - nuc_context\n",
    "#                 if start_idx < 0:\n",
    "#                     start_idx = 0\n",
    "#                     n_count = (i - nuc_context) * -1\n",
    "#                     beg_seq = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "#                 end_idx = i+step+nuc_context\n",
    "#                 if end_idx > len(chr_df):\n",
    "#                     end_idx = len(chr_df)\n",
    "#                     n_count = (i+step+nuc_context) - len(chr_df)\n",
    "#                     end_seq = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "\n",
    "#                 if beg_seq == [] and end_seq == []:\n",
    "#                     training_seq = chip_df[start_idx:end_idx].to_numpy()\n",
    "#                 elif beg_seq == [] and len(end_seq) != 0:\n",
    "#                     training_seq = chip_df[start_idx:end_idx].to_numpy() + np.array(end_seq)\n",
    "#                 elif len(beg_seq) != 0 and end_seq == []:\n",
    "#                     training_seq = beg_seq + chip_df[start_idx:end_idx].values.tolist()\n",
    "\n",
    "#                 #Save temp files for later concatenation\n",
    "#                 training_seq = np.array([training_seq], dtype=np.float32)\n",
    "#                 if j == 1: \n",
    "#                     training_data = training_seq\n",
    "#                 else:\n",
    "#                     training_data = np.append(training_data, training_seq, axis=0)\n",
    "#                 if j % 50 == 0:\n",
    "                    \n",
    "#                     np.savez_compressed(\"../data/tmp_chipData/tmp_{}.npz\".format(i), training_data)\n",
    "#                     file_names.append(\"../data/tmp_chipData/tmp_{}.npz\".format(i))\n",
    "#                     j = 1\n",
    "#                 else:\n",
    "#                     j+=1\n",
    "#         del training_data\n",
    "        \n",
    "#         print(\"     Finalizing training data...\")\n",
    "#         #Open numpy npz files and memmap them to reduce memory usage\n",
    "#         fpath = \"../data/chr_chipData/{}_chipData.dat\".format(chrom)\n",
    "#         rows = 0\n",
    "#         cols = None\n",
    "#         dtype = None\n",
    "#         for data_file in file_names:\n",
    "#             with np.load(data_file) as data:\n",
    "#                 for item in data.files:\n",
    "#                     chunk = data[item]\n",
    "#                     rows += chunk.shape[0]\n",
    "#                     cols = chunk.shape[1]\n",
    "#                     elements = chunk.shape[2]\n",
    "#                     dtype = chunk.dtype\n",
    "                \n",
    "#         merged = np.memmap(fpath, dtype=dtype, mode='w+', shape=(rows, cols, elements))\n",
    "#         idx = 0\n",
    "#         for data_file in file_names:\n",
    "#             with np.load(data_file) as data:\n",
    "#                 for item in data.files:\n",
    "#                     chunk = data[item]\n",
    "#                     merged[idx:idx + len(chunk)] = chunk\n",
    "#                     idx += len(chunk)\n",
    "        \n",
    "#         #Delete temp directories\n",
    "#         dir = '../data/tmp_chipData/'\n",
    "#         shutil.rmtree(dir)\n",
    "        \n",
    "#         print(\"Completed {}!\".format(chrom))\n",
    "#         print(\"Memmap object dimensions:\", rows, columns, elements)\n",
    "        \n",
    "#     print(\"Finished creating training data by chromosome!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9f2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modifyLabels(chromosomes, step=200, nuc_context=1000):\n",
    "#     pol3_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\"]\n",
    "#     pol3_df = pd.read_csv(\"../data/polr3d.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "#     rmsk_df = pd.read_csv(\"../data/mm10_rmsk.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "#     for chrom in chromosomes:\n",
    "#         print(chrom+\":\")\n",
    "#         print(\"     Creating necessary directories...\")\n",
    "#         output_dir1 = \"../data/tmp_seqData/\"\n",
    "#         output_dir2 = \"../data/chr_seqData/\"\n",
    "#         if not os.path.exists(output_dir1):\n",
    "#             os.makedirs(output_dir1)\n",
    "#         if not os.path.exists(output_dir2):\n",
    "#             os.makedirs(output_dir2)\n",
    "            \n",
    "#         #Process chromosome oe df to create training data\n",
    "#         print(\"     Processing one-hot encoded dataframe...\")\n",
    "#         chr_df = pd.read_csv(\"../chroms/oe_chroms/{}.csv\".format(chrom))\n",
    "#         chr_df[\"Label\"] = 0\n",
    "#         pol3_chr_df = pol3_df[pol3_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "#         rmsk_chr_df = rmsk_df[rmsk_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "        \n",
    "#         for row in range(len(rmsk_chr_df)):\n",
    "#             beg_range = rmsk_chr_df.iloc[row][\"Start\"]\n",
    "#             end_range = rmsk_chr_df.iloc[row][\"End\"]\n",
    "#             chr_df.loc[beg_range:end_range, \"Label\"] = 1\n",
    "#         for row in range(len(pol3_chr_df)):\n",
    "#             beg_range = pol3_chr_df.iloc[row][\"Start\"]\n",
    "#             end_range = pol3_chr_df.iloc[row][\"End\"]\n",
    "#             chr_df.loc[beg_range:end_range, \"Label\"] = 2\n",
    "            \n",
    "\n",
    "#         print(\"     Creating training data. This may take a while...\")\n",
    "#         #Start creating training data\n",
    "#         labels = []\n",
    "#         file_names = []\n",
    "#         final_data = []\n",
    "#         j = 1\n",
    "#         #Get first and last non-N index\n",
    "#         fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "#         for seq in fasta_sequences:\n",
    "#             name, sequence = seq.id, str(seq.seq)\n",
    "#         a_idx = sequence.lower().index(\"a\")\n",
    "#         c_idx = sequence.lower().index(\"c\")\n",
    "#         g_idx = sequence.lower().index(\"g\")\n",
    "#         t_idx = sequence.lower().index(\"t\")\n",
    "#         chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "#         a_idx = sequence.lower().rfind(\"a\")\n",
    "#         c_idx = sequence.lower().rfind(\"c\")\n",
    "#         g_idx = sequence.lower().rfind(\"g\")\n",
    "#         t_idx = sequence.lower().rfind(\"t\")\n",
    "#         chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "#         for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "#             if i <= chr_end_idx:\n",
    "#                 beg_seq = []\n",
    "#                 end_seq = []\n",
    "                \n",
    "#                 start_idx = i - nuc_context\n",
    "#                 if start_idx < 0:\n",
    "#                     start_idx = 0\n",
    "#                     n_count = (i - nuc_context) * -1\n",
    "#                     beg_seq = [[0,0,0,0]] * n_count\n",
    "#                 end_idx = i+step+nuc_context\n",
    "#                 if end_idx > len(chr_df):\n",
    "#                     end_idx = len(chr_df)\n",
    "#                     n_count = (i+step+nuc_context) - len(chr_df)\n",
    "#                     end_seq = [[0,0,0,0]] * n_count\n",
    "\n",
    "#                 #Determine labels    \n",
    "#                 tmp_df = chr_df[start_idx:end_idx]\n",
    "#                 grouped_df = tmp_df.groupby(\"Label\").count().reset_index()\n",
    "#                 try:\n",
    "#                     if grouped_df[grouped_df[\"Label\"] == 2][\"Unnamed: 0\"][2] >= 65:\n",
    "#                         labels.append([1])\n",
    "#                     elif grouped_df[grouped_df[\"Label\"] == 1][\"Unnamed: 0\"][2] >= 65:\n",
    "#                         labels.append([2])\n",
    "#                     else:\n",
    "#                         labels.append([0])\n",
    "#                 except KeyError:\n",
    "#                     try:\n",
    "#                         if grouped_df[grouped_df[\"Label\"] == 1][\"Unnamed: 0\"][2] >= 65:\n",
    "#                             labels.append([1])\n",
    "#                         else:\n",
    "#                             labels.append([0])\n",
    "#                     except KeyError:\n",
    "#                         labels.append([0])\n",
    "        \n",
    "#         print(\"     Finalizing training data...\")\n",
    "\n",
    "                \n",
    "#         #Save chr data\n",
    "#         labels = np.array(labels)\n",
    "#         fpath2 = \"../data/chr_seqData/{}_labelsData.npz\".format(chrom)\n",
    "#         np.savez_compressed(fpath2, labels=labels)\n",
    "        \n",
    "        \n",
    "#         print(\"Completed {}!\".format(chrom))\n",
    "        \n",
    "#     print(\"Finished modifying labels data by chromosome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b6695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "856048c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPol3Data(chromosomes, dt=\"training\", step=200, nuc_context=1000):\n",
    "    pol3_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\"]\n",
    "    pol3_df = pd.read_csv(\"../data/polr3d.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "    rmsk_df = pd.read_csv(\"../data/mm10_rmsk.bed\", sep=\"\\s+\", header=None, names=pol3_bed_cols_names)\n",
    "    nucOE_df = pd.DataFrame({\"Nucleotide\": [\"a\", \"c\", \"g\", \"t\", \"n\"], \"OE\": [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1],[0,0,0,0]]})\n",
    "    j = 1\n",
    "    \n",
    "    print(\"Reading in ChIP files...\")\n",
    "    chip_dfs = []\n",
    "    chip_names = []\n",
    "    chip_bed_cols_names = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\", \"signalValue\", \"pValue\", \"qValue\", \"peak\"]\n",
    "    for chip in glob.glob(\"../data/chip_data/*\"):\n",
    "        tmp_chip_df = pd.read_csv(chip, sep=\"\\s+\", header=None, names=chip_bed_cols_names)\n",
    "        chip_dfs.append(tmp_chip_df)\n",
    "        chip_names.append(chip.split(\"/\")[-1].split(\".\")[0])\n",
    "    del tmp_chip_df\n",
    "        \n",
    "    for chrom in chromosomes:\n",
    "        print(chrom+\":\")\n",
    "        print(\"     Creating necessary directories...\")\n",
    "        output_dir1 = \"../data/mlData/\"\n",
    "        if not os.path.exists(output_dir1):\n",
    "            os.makedirs(output_dir1)\n",
    "            \n",
    "        #Process chromosome oe df to create training data\n",
    "        print(\"     Processing FASTA sequence...\")\n",
    "        fasta_sequences = SeqIO.parse(open(\"../chroms/{}.fa\".format(chrom)),'fasta')\n",
    "        for seq in fasta_sequences:\n",
    "            name, sequence = seq.id, str(seq.seq).lower()\n",
    "        del fasta_sequences\n",
    "        chr_df = pd.DataFrame({\"Nucleotide\": list(sequence)})\n",
    "        chr_df[\"Label\"] = 0\n",
    "        pol3_chr_df = pol3_df[pol3_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "        rmsk_chr_df = rmsk_df[rmsk_df[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "        \n",
    "        for row in range(len(rmsk_chr_df)):\n",
    "            beg_range = rmsk_chr_df.iloc[row][\"Start\"]\n",
    "            end_range = rmsk_chr_df.iloc[row][\"End\"]\n",
    "            chr_df.loc[beg_range:end_range, \"Label\"] = 1\n",
    "        for row in range(len(pol3_chr_df)):\n",
    "            beg_range = pol3_chr_df.iloc[row][\"Start\"]\n",
    "            end_range = pol3_chr_df.iloc[row][\"End\"]\n",
    "            chr_df.loc[beg_range:end_range, \"Label\"] = 2\n",
    "        del pol3_chr_df\n",
    "        del rmsk_chr_df\n",
    "                        \n",
    "        #Create ChIP df that is ready to be converted to numpy training data\n",
    "        print(\"     Processing ChIP data...\")\n",
    "        chip_df = pd.DataFrame(index=np.arange(len(chr_df))).reset_index().drop(columns=\"index\")\n",
    "        chip_idx = 0\n",
    "        for chip in chip_dfs:\n",
    "            tmp_chip_chr_df = chip[chip[\"Chromosome\"] == \"{}\".format(chrom)]\n",
    "            chip_df[chip_names[chip_idx]] = 0.\n",
    "            \n",
    "            for row in range(len(tmp_chip_chr_df)):\n",
    "                beg_range = tmp_chip_chr_df.iloc[row][\"Start\"]\n",
    "                end_range = tmp_chip_chr_df.iloc[row][\"End\"]\n",
    "                chip_df.loc[beg_range:end_range, chip_names[chip_idx]] = tmp_chip_chr_df.iloc[row][\"signalValue\"]\n",
    "            chip_idx+=1\n",
    "\n",
    "        print(\"     Creating data for model. This may take a while...\")\n",
    "        #Start creating training data\n",
    "        labels = []\n",
    "        #Get first and last non-N index\n",
    "        a_idx = sequence.index(\"a\")\n",
    "        c_idx = sequence.index(\"c\")\n",
    "        g_idx = sequence.index(\"g\")\n",
    "        t_idx = sequence.index(\"t\")\n",
    "        chr_start_idx = min(a_idx,c_idx,g_idx,t_idx)\n",
    "        a_idx = sequence.rfind(\"a\")\n",
    "        c_idx = sequence.rfind(\"c\")\n",
    "        g_idx = sequence.rfind(\"g\")\n",
    "        t_idx = sequence.rfind(\"t\")\n",
    "        chr_end_idx = max(a_idx,c_idx,g_idx,t_idx)\n",
    "        for i in range(chr_start_idx, chr_end_idx+1, step):\n",
    "            if i <= chr_end_idx:\n",
    "                beg_seq = []\n",
    "                end_seq = []\n",
    "                \n",
    "                beg_chip = []\n",
    "                end_chip = []\n",
    "                \n",
    "                start_idx = i - nuc_context\n",
    "                if start_idx < 0:\n",
    "                    start_idx = 0\n",
    "                    n_count = (i - nuc_context) * -1\n",
    "                    beg_seq = [[0,0,0,0]] * n_count\n",
    "                    beg_chip = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "                end_idx = i+step+nuc_context\n",
    "                if end_idx > len(chr_df):\n",
    "                    end_idx = len(chr_df)\n",
    "                    n_count = (i+step+nuc_context) - len(chr_df)\n",
    "                    end_seq = [[0,0,0,0]] * n_count\n",
    "                    end_chip = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]] * n_count\n",
    "                    \n",
    "                #Determine labels    \n",
    "                tmp_df = chr_df[i:i+step]\n",
    "                grouped_df = tmp_df.groupby(\"Label\").count().reset_index()\n",
    "                grouped_df.index = grouped_df[\"Label\"]\n",
    "                try:\n",
    "                    if grouped_df[grouped_df[\"Label\"] == 2][\"Nucleotide\"][2] >= 65:\n",
    "                        label = [1]\n",
    "                    elif grouped_df[grouped_df[\"Label\"] == 1][\"Nucleotide\"][1] >= 65:\n",
    "                        label = [0]\n",
    "                    else:\n",
    "                        label = [2]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        if grouped_df[grouped_df[\"Label\"] == 1][\"Nucleotide\"][1] >= 65:\n",
    "                            label = [0]\n",
    "                        else:\n",
    "                            label = [2]\n",
    "                    except KeyError:\n",
    "                        label = [2]\n",
    "                del tmp_df\n",
    "                del grouped_df\n",
    "                        \n",
    "                if label == [0] or label == [1]:\n",
    "                    #Used to randomly select which nucleotide sequences with label [0] are in datasets\n",
    "                    if label == [0]:\n",
    "                        random_num = random.randint(-1000,1)\n",
    "                    if (label == [0] and random_num > 0) or (label == [1]):                             \n",
    "                        curr_chr_df = chr_df[start_idx:end_idx].merge(nucOE_df, on=[\"Nucleotide\"], how=\"left\")\n",
    "\n",
    "                        if beg_seq == [] and end_seq == []:\n",
    "                            curr_seq = curr_chr_df[\"OE\"].tolist()\n",
    "                        elif beg_seq == [] and len(end_seq) != 0:\n",
    "                            curr_seq = curr_chr_df[\"OE\"].tolist() + end_seq\n",
    "                        elif len(beg_seq) != 0 and end_seq == []:\n",
    "                            curr_seq = beg_seq + curr_chr_df[\"OE\"].tolist()\n",
    "                        del curr_chr_df\n",
    "\n",
    "                        if beg_chip == [] and end_chip == []:\n",
    "                            curr_chip = chip_df[start_idx:end_idx].values.tolist()\n",
    "                        elif beg_chip == [] and len(end_chip) != 0:\n",
    "                            curr_chip = chip_df[start_idx:end_idx].values.tolist() + end_chip\n",
    "                        elif len(beg_chip) != 0 and end_chip == []:\n",
    "                            curr_chip = beg_chip + chip_df[start_idx:end_idx].values.tolist()\n",
    "\n",
    "                        #Save current sequences\n",
    "                        curr_seq = np.array([curr_seq], dtype=np.uint16)\n",
    "                        curr_chip = np.array([curr_chip], dtype=np.float64)\n",
    "                        labels.append(label)\n",
    "                        if j == 1: \n",
    "                            seq_data = curr_seq\n",
    "                            chip_data = curr_chip\n",
    "                            j+=1\n",
    "                        else:\n",
    "                            seq_data = np.append(seq_data, curr_seq, axis=0)\n",
    "                            chip_data = np.append(chip_data, curr_chip, axis=0)\n",
    "                        del curr_seq\n",
    "                        del curr_chip\n",
    "\n",
    "        print(\"Completed {}!\".format(chrom))\n",
    "\n",
    "    print(\"Finalizing data...\")\n",
    "    labels = np.array(labels)\n",
    "    true_idx = np.where(labels == [1])[0]\n",
    "    false_idx = np.where(labels == [0])[0]\n",
    "\n",
    "    #Shuffle and subset indeces for training and testing datasets\n",
    "\n",
    "    np.random.shuffle(false_idx)\n",
    "    false_idx = false_idx[:len(true_idx)]\n",
    "    seq_data = np.append(seq_data[true_idx], seq_data[false_idx], axis=0)\n",
    "    chip_data = np.append(chip_data[true_idx], chip_data[false_idx], axis=0)\n",
    "    \n",
    "    labels = np.append(labels[true_idx], labels[false_idx], axis=0)\n",
    "    \n",
    "    final_idx = np.random.permutation(len(labels))\n",
    "    seq_data = seq_data[final_idx]\n",
    "    chip_data = chip_data[final_idx]\n",
    "    labels = labels[final_idx]\n",
    "    \n",
    "    np.savez_compressed(\"../data/mlData/{}_seqData.npz\".format(dt), dna=seq_data, label=labels)\n",
    "    np.savez_compressed(\"../data/mlData/{}_chipData.npz\".format(dt), chip=chip_data, label=labels)\n",
    "        \n",
    "    print(\"Finished creating data!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10287186",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_chroms = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\",\n",
    "                  \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"]\n",
    "testing_chroms = [\"chr7\", \"chr8\"]\n",
    "all_chroms = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\",\n",
    "                  \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "716df38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in ChIP files...\n",
      "chr7:\n",
      "     Creating necessary directories...\n",
      "     Processing FASTA sequence...\n",
      "     Processing ChIP data...\n",
      "     Creating data for model. This may take a while...\n",
      "Completed chr7!\n",
      "chr8:\n",
      "     Creating necessary directories...\n",
      "     Processing FASTA sequence...\n",
      "     Processing ChIP data...\n",
      "     Creating data for model. This may take a while...\n",
      "Completed chr8!\n",
      "Finalizing data...\n",
      "Finished creating data!\n"
     ]
    }
   ],
   "source": [
    "createPol3Data(testing_chroms, dt=\"testing\", step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51b9f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in ChIP files...\n",
      "chr1:\n",
      "     Creating necessary directories...\n",
      "     Processing FASTA sequence...\n",
      "     Processing ChIP data...\n",
      "     Creating data for model. This may take a while...\n",
      "Completed chr1!\n",
      "chr2:\n",
      "     Creating necessary directories...\n",
      "     Processing FASTA sequence...\n",
      "     Processing ChIP data...\n",
      "     Creating data for model. This may take a while...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreatePol3Data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_chroms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnuc_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mcreatePol3Data\u001b[0;34m(chromosomes, dt, step, nuc_context)\u001b[0m\n\u001b[1;32m     99\u001b[0m grouped_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m grouped_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgrouped_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrouped_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNucleotide\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65\u001b[39m:\n\u001b[1;32m    102\u001b[0m         label \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m grouped_df[grouped_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNucleotide\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:3752\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3750\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3754\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3755\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3756\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3810\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 3811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   3941\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m   3929\u001b[0m     ):\n\u001b[1;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3934\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:747\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[1;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    753\u001b[0m             ),\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 748\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/array_algos/take.py:133\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m--> 133\u001b[0m dtype, fill_value, mask_info \u001b[38;5;241m=\u001b[39m \u001b[43m_take_preprocess_indexer_and_fill_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m flip_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/array_algos/take.py:592\u001b[0m, in \u001b[0;36m_take_preprocess_indexer_and_fill_value\u001b[0;34m(arr, indexer, fill_value, allow_fill, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m         mask_info \u001b[38;5;241m=\u001b[39m mask, needs_masking\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_masking:\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# if not, then depromote, set fill_value to dummy\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# (it won't be used but we don't want the cython code\u001b[39;00m\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;66;03m# to crash when trying to cast it to dtype)\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m             dtype, fill_value \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype, \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype, fill_value, mask_info\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "createPol3Data(training_chroms, dt=\"training\", step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createSeqData(all_chroms, step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createChipData(all_chroms, step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifyLabels([\"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"], step=200, nuc_context=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb2cb9",
   "metadata": {},
   "source": [
    "## Create final training data from chromosome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b791a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_rows = [1244650,1210850,991100,950950,907300,853400,796600,725050,691600,668850,675050,666250,491750,454400,\n",
    "#            424900,451050,415900,401250,292700,321350,208450,201450,780100,286000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"seq\"\n",
    "# idx = 0\n",
    "# for chrom in all_chroms:\n",
    "#     print(chrom)\n",
    "#     labels = np.load(\"../data/chr_seqData/{}_labelsData.npz\".format(chrom))\n",
    "#     for item in labels.files:\n",
    "#         true_idx = np.where(labels[item] == [1])[0]\n",
    "#         false_idx = np.where(labels[item] == [0])[0]\n",
    "        \n",
    "#     #Shuffle and subset indeces for training and testing datasets\n",
    "#     np.random.shuffle(true_idx)\n",
    "#     training_true_idx = true_idx[:int(len(true_idx)*0.9)]\n",
    "#     testing_true_idx = true_idx[int(len(true_idx)*0.9)+1:]\n",
    "    \n",
    "#     np.random.shuffle(false_idx)\n",
    "#     training_false_idx = false_idx[:int(len(true_idx)*0.9)]\n",
    "#     testing_false_idx = false_idx[int(len(true_idx)*0.9)+1:len(true_idx)]\n",
    "    \n",
    "#     if data == \"seq\":\n",
    "#         dtype = np.uint16\n",
    "#         elements = 4\n",
    "#         name = \"Sequence\"\n",
    "#     elif data == \"chip\":\n",
    "#         dtype = np.float32\n",
    "#         elements = 20\n",
    "#         name = \"Chip\"\n",
    "    \n",
    "#     chr_seq = np.memmap(\"../data/chr_{}Data/{}_{}Data.dat\".format(data,chrom,data), dtype=dtype, mode='r', shape=(seq_rows[idx],2200,elements))\n",
    "#     chr_seq_true_training = chr_seq[training_true_idx]\n",
    "#     chr_seq_true_testing = chr_seq[testing_true_idx]\n",
    "#     chr_seq_false_training = chr_seq[training_false_idx]\n",
    "#     chr_seq_false_testing = chr_seq[testing_false_idx]\n",
    "    \n",
    "#     #Append data to respective matrix\n",
    "#     if idx == 0:\n",
    "#         chr_seq_training = np.append(chr_seq_true_training, chr_seq_false_training, axis=0)\n",
    "#         chr_seq_testing = np.append(chr_seq_true_testing, chr_seq_false_testing, axis=0)\n",
    "#     else:\n",
    "#         chr_seq_training = np.append(chr_seq_training, np.append(chr_seq_true_training, chr_seq_false_training, axis=0), axis=0)\n",
    "#         chr_seq_testing = np.append(chr_seq_testing, np.append(chr_seq_true_testing, chr_seq_false_testing, axis=0), axis=0)\n",
    "        \n",
    "#     #Keep track of labels\n",
    "#     for item in labels.files:\n",
    "#         if idx == 0:\n",
    "#             final_labels_training = labels[item][training_true_idx]\n",
    "#             final_labels_training = np.append(final_labels_training, labels[item][training_false_idx], axis=0)\n",
    "            \n",
    "#             final_labels_testing = labels[item][testing_true_idx]\n",
    "#             final_labels_testing = np.append(final_labels_testing, labels[item][testing_false_idx], axis=0)\n",
    "#         else:\n",
    "#             final_labels_training = np.append(final_labels_training, labels[item][training_true_idx], axis=0)\n",
    "#             final_labels_training = np.append(final_labels_training, labels[item][training_false_idx], axis=0)\n",
    "            \n",
    "#             final_labels_testing = np.append(final_labels_testing, labels[item][testing_true_idx], axis=0)\n",
    "#             final_labels_testing = np.append(final_labels_testing, labels[item][testing_false_idx], axis=0)\n",
    "        \n",
    "#     idx+=1\n",
    "\n",
    "# #Shuffle indeces\n",
    "# training_idx = np.random.permutation(len(final_labels_training))\n",
    "# chr_seq_training = chr_seq_training[training_idx]\n",
    "# final_labels_training = final_labels_training[training_idx]\n",
    "\n",
    "# testing_idx = np.random.permutation(len(final_labels_testing))\n",
    "# chr_seq_testing = chr_seq_testing[testing_idx]\n",
    "# final_labels_testing = final_labels_testing[testing_idx]\n",
    "\n",
    "# if data == \"seq\":\n",
    "#     np.savez_compressed(\"../data/final_data/training{}.npz\".format(name), dna=chr_seq_training, labels=final_labels_training, dtype=np.int8)\n",
    "#     np.savez_compressed(\"../data/final_data/testing{}.npz\".format(name), dna=chr_seq_testing, labels=final_labels_testing, dtype=np.int8)\n",
    "# elif data == \"chip\":\n",
    "#     np.savez_compressed(\"../data/final_data/training{}.npz\".format(name), chip=chr_seq_training, labels=final_labels_training, dtype=np.float32)\n",
    "#     np.savez_compressed(\"../data/final_data/testing{}.npz\".format(name), chip=chr_seq_testing, labels=final_labels_testing, dtype=np.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909f037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
